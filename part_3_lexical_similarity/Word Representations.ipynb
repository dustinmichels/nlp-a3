{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Representations and Lexical Similarities (12 + 10 pt)\n",
    "\n",
    "For more reading on vector semantics got to Chapter 6, sections 6.4 and 6.8:\n",
    "https://web.stanford.edu/~jurafsky/slp3/6.pdf\n",
    "\n",
    "For wordnet exploration use this manual: https://www.nltk.org/howto/wordnet.html\n",
    "\n",
    "For additional wordnet discussions go to chapter 19: https://web.stanford.edu/~jurafsky/slp3/19.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wordnet\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# load word-vector glov\n",
    "import gensim.downloader as gensim_api\n",
    "glove_model = gensim_api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "from itertools import combinations, product\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_words = ['car', 'dog', 'banana', 'delicious', 'baguette', 'jumping', 'hugging', 'election']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Word Representations in English WordNet (+3pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---car---\n",
      "\n",
      "car.n.01 - a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "  lemmas: ['car', 'auto', 'automobile', 'machine', 'motorcar']\n",
      "  hypernyms: ['motor_vehicle.n.01']\n",
      "  hypernyms: ['ambulance.n.01', 'beach_wagon.n.01', 'bus.n.04', 'cab.n.03', 'compact.n.03', 'convertible.n.01', 'coupe.n.01', 'cruiser.n.01', 'electric.n.01', 'gas_guzzler.n.01', 'hardtop.n.01', 'hatchback.n.01', 'horseless_carriage.n.01', 'hot_rod.n.01', 'jeep.n.01', 'limousine.n.01', 'loaner.n.02', 'minicar.n.01', 'minivan.n.01', 'model_t.n.01', 'pace_car.n.01', 'racer.n.02', 'roadster.n.01', 'sedan.n.01', 'sport_utility.n.01', 'sports_car.n.01', 'stanley_steamer.n.01', 'stock_car.n.01', 'subcompact.n.01', 'touring_car.n.01', 'used-car.n.01']\n",
      "\n",
      "car.n.02 - a wheeled vehicle adapted to the rails of railroad\n",
      "  lemmas: ['car', 'railcar', 'railway_car', 'railroad_car']\n",
      "  hypernyms: ['wheeled_vehicle.n.01']\n",
      "  hypernyms: ['baggage_car.n.01', 'cabin_car.n.01', 'club_car.n.01', 'freight_car.n.01', \"guard's_van.n.01\", 'handcar.n.01', 'mail_car.n.01', 'passenger_car.n.01', 'slip_coach.n.01', 'tender.n.04', 'van.n.03']\n",
      "\n",
      "car.n.03 - the compartment that is suspended from an airship and that carries personnel and the cargo and the power plant\n",
      "  lemmas: ['car', 'gondola']\n",
      "  hypernyms: ['compartment.n.02']\n",
      "  hypernyms: []\n",
      "\n",
      "car.n.04 - where passengers ride up and down\n",
      "  lemmas: ['car', 'elevator_car']\n",
      "  hypernyms: ['compartment.n.02']\n",
      "  hypernyms: []\n",
      "\n",
      "cable_car.n.01 - a conveyance for passengers or freight on a cable railway\n",
      "  lemmas: ['cable_car', 'car']\n",
      "  hypernyms: ['compartment.n.02']\n",
      "  hypernyms: []\n",
      "\n",
      "\n",
      "---dog---\n",
      "\n",
      "dog.n.01 - a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "  lemmas: ['dog', 'domestic_dog', 'Canis_familiaris']\n",
      "  hypernyms: ['canine.n.02', 'domestic_animal.n.01']\n",
      "  hypernyms: ['basenji.n.01', 'corgi.n.01', 'cur.n.01', 'dalmatian.n.02', 'great_pyrenees.n.01', 'griffon.n.02', 'hunting_dog.n.01', 'lapdog.n.01', 'leonberg.n.01', 'mexican_hairless.n.01', 'newfoundland.n.01', 'pooch.n.01', 'poodle.n.01', 'pug.n.01', 'puppy.n.01', 'spitz.n.01', 'toy_dog.n.01', 'working_dog.n.01']\n",
      "\n",
      "frump.n.01 - a dull unattractive unpleasant girl or woman\n",
      "  lemmas: ['frump', 'dog']\n",
      "  hypernyms: ['unpleasant_woman.n.01']\n",
      "  hypernyms: []\n",
      "\n",
      "dog.n.03 - informal term for a man\n",
      "  lemmas: ['dog']\n",
      "  hypernyms: ['chap.n.01']\n",
      "  hypernyms: []\n",
      "\n",
      "cad.n.01 - someone who is morally reprehensible\n",
      "  lemmas: ['cad', 'bounder', 'blackguard', 'dog', 'hound', 'heel']\n",
      "  hypernyms: ['villain.n.01']\n",
      "  hypernyms: ['perisher.n.01']\n",
      "\n",
      "frank.n.02 - a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll\n",
      "  lemmas: ['frank', 'frankfurter', 'hotdog', 'hot_dog', 'dog', 'wiener', 'wienerwurst', 'weenie']\n",
      "  hypernyms: ['sausage.n.01']\n",
      "  hypernyms: ['vienna_sausage.n.01']\n",
      "\n",
      "pawl.n.01 - a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward\n",
      "  lemmas: ['pawl', 'detent', 'click', 'dog']\n",
      "  hypernyms: ['catch.n.06']\n",
      "  hypernyms: []\n",
      "\n",
      "andiron.n.01 - metal supports for logs in a fireplace\n",
      "  lemmas: ['andiron', 'firedog', 'dog', 'dog-iron']\n",
      "  hypernyms: ['support.n.10']\n",
      "  hypernyms: []\n",
      "\n",
      "chase.v.01 - go after with the intent to catch\n",
      "  lemmas: ['chase', 'chase_after', 'trail', 'tail', 'tag', 'give_chase', 'dog', 'go_after', 'track']\n",
      "  hypernyms: ['pursue.v.02']\n",
      "  hypernyms: ['hound.v.01', 'quest.v.02', 'run_down.v.07', 'tree.v.03']\n",
      "\n",
      "\n",
      "---banana---\n",
      "\n",
      "banana.n.01 - any of several tropical and subtropical treelike herbs of the genus Musa having a terminal crown of large entire leaves and usually bearing hanging clusters of elongated fruits\n",
      "  lemmas: ['banana', 'banana_tree']\n",
      "  hypernyms: ['herb.n.01']\n",
      "  hypernyms: ['abaca.n.02', 'dwarf_banana.n.01', 'edible_banana.n.01', 'japanese_banana.n.01', 'plantain.n.02']\n",
      "\n",
      "banana.n.02 - elongated crescent-shaped yellow fruit with soft sweet flesh\n",
      "  lemmas: ['banana']\n",
      "  hypernyms: ['edible_fruit.n.01']\n",
      "  hypernyms: []\n",
      "\n",
      "\n",
      "---delicious---\n",
      "\n",
      "delicious.n.01 - variety of sweet eating apples\n",
      "  lemmas: ['Delicious']\n",
      "  hypernyms: ['eating_apple.n.01']\n",
      "  hypernyms: ['golden_delicious.n.01', 'red_delicious.n.01']\n",
      "\n",
      "delightful.s.01 - greatly pleasing or entertaining\n",
      "  lemmas: ['delightful', 'delicious']\n",
      "  hypernyms: []\n",
      "  hypernyms: []\n",
      "\n",
      "delectable.s.01 - extremely pleasing to the sense of taste\n",
      "  lemmas: ['delectable', 'delicious', 'luscious', 'pleasant-tasting', 'scrumptious', 'toothsome', 'yummy']\n",
      "  hypernyms: []\n",
      "  hypernyms: []\n",
      "\n",
      "\n",
      "---baguette---\n",
      "\n",
      "baguet.n.01 - narrow French stick loaf\n",
      "  lemmas: ['baguet', 'baguette']\n",
      "  hypernyms: ['french_bread.n.01']\n",
      "  hypernyms: []\n",
      "\n",
      "\n",
      "---jumping---\n",
      "\n",
      "jumping.n.01 - the act of participating in an athletic competition in which you must jump\n",
      "  lemmas: ['jumping']\n",
      "  hypernyms: ['track_and_field.n.01']\n",
      "  hypernyms: ['broad_jump.n.02', 'high_jump.n.02']\n",
      "\n",
      "jump.n.06 - the act of jumping; propelling yourself off the ground\n",
      "  lemmas: ['jump', 'jumping']\n",
      "  hypernyms: ['propulsion.n.02']\n",
      "  hypernyms: ['capriole.n.01', 'header.n.07', 'hop.n.01', 'jumping_up_and_down.n.01', 'leap.n.01', 'vault.n.04']\n",
      "\n",
      "jump.v.01 - move forward by leaps and bounds\n",
      "  lemmas: ['jump', 'leap', 'bound', 'spring']\n",
      "  hypernyms: ['move.v.03']\n",
      "  hypernyms: ['bounce.v.01', 'bounce.v.05', 'burst.v.04', 'caper.v.01', 'capriole.v.01', 'curvet.v.01', 'galumph.v.01', 'hop.v.01', 'hop.v.06', 'leapfrog.v.01', 'pronk.v.01', 'saltate.v.02', 'ski_jump.v.01', 'vault.v.01', 'vault.v.02']\n",
      "\n",
      "startle.v.02 - move or jump suddenly, as if in surprise or alarm\n",
      "  lemmas: ['startle', 'jump', 'start']\n",
      "  hypernyms: ['move.v.03']\n",
      "  hypernyms: ['boggle.v.01', 'jackrabbit.v.01', 'rear_back.v.02', 'shy.v.01']\n",
      "\n",
      "jump.v.03 - make a sudden physical attack on\n",
      "  lemmas: ['jump']\n",
      "  hypernyms: ['assail.v.01']\n",
      "  hypernyms: []\n",
      "\n",
      "jump.v.04 - increase suddenly and significantly\n",
      "  lemmas: ['jump']\n",
      "  hypernyms: ['wax.v.02']\n",
      "  hypernyms: []\n",
      "\n",
      "leap_out.v.01 - be highly noticeable\n",
      "  lemmas: ['leap_out', 'jump_out', 'jump', 'stand_out', 'stick_out']\n",
      "  hypernyms: ['look.v.02']\n",
      "  hypernyms: []\n",
      "\n",
      "jump.v.06 - enter eagerly into\n",
      "  lemmas: ['jump']\n",
      "  hypernyms: ['enter.v.02']\n",
      "  hypernyms: []\n",
      "\n",
      "rise.v.11 - rise in rank or status\n",
      "  lemmas: ['rise', 'jump', 'climb_up']\n",
      "  hypernyms: ['change.v.02']\n",
      "  hypernyms: []\n",
      "\n",
      "jump.v.08 - jump down from an elevated point\n",
      "  lemmas: ['jump', 'leap', 'jump_off']\n",
      "  hypernyms: ['move.v.03']\n",
      "  hypernyms: []\n",
      "\n",
      "derail.v.02 - run off or leave the rails\n",
      "  lemmas: ['derail', 'jump']\n",
      "  hypernyms: ['travel.v.01']\n",
      "  hypernyms: []\n",
      "\n",
      "chute.v.01 - jump from an airplane and descend with a parachute\n",
      "  lemmas: ['chute', 'parachute', 'jump']\n",
      "  hypernyms: ['dive.v.01']\n",
      "  hypernyms: ['sky_dive.v.01']\n",
      "\n",
      "jump.v.11 - cause to jump or leap\n",
      "  lemmas: ['jump', 'leap']\n",
      "  hypernyms: []\n",
      "  hypernyms: []\n",
      "\n",
      "jumpstart.v.01 - start (a car engine whose battery is dead) by connecting it to another car's battery\n",
      "  lemmas: ['jumpstart', 'jump-start', 'jump']\n",
      "  hypernyms: ['start.v.08']\n",
      "  hypernyms: []\n",
      "\n",
      "jump.v.13 - bypass\n",
      "  lemmas: ['jump', 'pass_over', 'skip', 'skip_over']\n",
      "  hypernyms: ['neglect.v.01']\n",
      "  hypernyms: []\n",
      "\n",
      "leap.v.02 - pass abruptly from one state or topic to another\n",
      "  lemmas: ['leap', 'jump']\n",
      "  hypernyms: ['switch.v.03']\n",
      "  hypernyms: []\n",
      "\n",
      "alternate.v.01 - go back and forth; swing back and forth between two states or conditions\n",
      "  lemmas: ['alternate', 'jump']\n",
      "  hypernyms: ['change.v.03']\n",
      "  hypernyms: []\n",
      "\n",
      "\n",
      "---hugging---\n",
      "\n",
      "caressing.n.01 - affectionate play (or foreplay without contact with the genital organs)\n",
      "  lemmas: ['caressing', 'cuddling', 'fondling', 'hugging', 'kissing', 'necking', 'petting', 'smooching', 'snuggling']\n",
      "  hypernyms: ['foreplay.n.01']\n",
      "  hypernyms: ['snogging.n.01']\n",
      "\n",
      "embrace.v.02 - squeeze (someone) tightly in your arms, usually with fondness\n",
      "  lemmas: ['embrace', 'hug', 'bosom', 'squeeze']\n",
      "  hypernyms: ['clasp.v.01']\n",
      "  hypernyms: ['clinch.v.04', 'cuddle.v.02', 'interlock.v.03']\n",
      "\n",
      "hug.v.02 - fit closely or tightly\n",
      "  lemmas: ['hug']\n",
      "  hypernyms: ['touch.v.05']\n",
      "  hypernyms: []\n",
      "\n",
      "\n",
      "---election---\n",
      "\n",
      "election.n.01 - a vote to select the winner of a position or political office\n",
      "  lemmas: ['election']\n",
      "  hypernyms: ['vote.n.02']\n",
      "  hypernyms: ['by-election.n.01', 'general_election.n.01', 'primary.n.01', 'reelection.n.01', 'runoff.n.02']\n",
      "\n",
      "election.n.02 - the act of selecting someone or something; the exercise of deliberate choice\n",
      "  lemmas: ['election']\n",
      "  hypernyms: ['choice.n.02']\n",
      "  hypernyms: ['co-option.n.01', 'cumulative_vote.n.01']\n",
      "\n",
      "election.n.03 - the status or fact of being elected\n",
      "  lemmas: ['election']\n",
      "  hypernyms: ['status.n.01']\n",
      "  hypernyms: []\n",
      "\n",
      "election.n.04 - the predestination of some individuals as objects of divine mercy (especially as conceived by Calvinists)\n",
      "  lemmas: ['election']\n",
      "  hypernyms: ['predestination.n.02']\n",
      "  hypernyms: []\n"
     ]
    }
   ],
   "source": [
    "# For each word above print their synsets\n",
    "# for each synset print all lemmas, hypernyms, hyponyms\n",
    "\n",
    "for word in some_words:\n",
    "    print(f\"\\n\\n---{word}---\")\n",
    "    synset = wn.synsets(word)\n",
    "    #print(synset)\n",
    "    for s in synset:\n",
    "        print()\n",
    "        print(s.name(), \"-\", s.definition())\n",
    "        print(\"  lemmas:\", [x.name() for x in s.lemmas()])\n",
    "        print(\"  hypernyms:\", [x.name() for x in s.hypernyms()])\n",
    "        print(\"  hypernyms:\", [x.name() for x in s.hyponyms()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure The Lexical Similarity (+3pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car       dog        0.667\n",
      "car       banana     0.421\n",
      "car       delicious  0.364\n",
      "car       baguette   0.211\n",
      "car       jumping    0.125\n",
      "car       hugging    0.235\n",
      "car       election   0.133\n",
      "dog       banana     0.632\n",
      "dog       delicious  0.556\n",
      "dog       baguette   0.556\n",
      "dog       jumping    0.333\n",
      "dog       hugging    0.286\n",
      "dog       election   0.182\n",
      "banana    delicious  0.750\n",
      "banana    baguette   0.556\n",
      "banana    jumping    0.133\n",
      "banana    hugging    0.250\n",
      "banana    election   0.143\n",
      "delicious baguette   0.500\n",
      "delicious jumping    0.118\n",
      "delicious hugging    0.222\n",
      "delicious election   0.125\n",
      "baguette  jumping    0.118\n",
      "baguette  hugging    0.222\n",
      "baguette  election   0.125\n",
      "jumping   hugging    0.400\n",
      "jumping   election   0.667\n",
      "hugging   election   0.200\n"
     ]
    }
   ],
   "source": [
    "# Wu-Palmer Similarity is a measure of similarity between to sense based on their depth distance. \n",
    "#\n",
    "# For each pair of words, find their closest sense based on Wu-Palmer Similarity.\n",
    "# List all word pairs and their highest possible wup_similarity. \n",
    "# Use wn.wup_similarity(s1, s2) and itertools (combinations and product).\n",
    "# if there is no connection between two words, put 0.\n",
    "\n",
    "wn_sims = []\n",
    "for word1, word2 in combinations(some_words, 2):    \n",
    "    # check similarities of all senses for words\n",
    "    similarities = []\n",
    "    for s1 in wn.synsets(word1):\n",
    "        for s2 in wn.synsets(word2):\n",
    "            sim = wn.wup_similarity(s1, s2)\n",
    "            sim = sim if sim else 0\n",
    "            similarities.append((s1, s2, sim))\n",
    "            \n",
    "    max_sim = max(similarities, key=lambda x: x[2])[2]\n",
    "\n",
    "    wn_sims.append(max_sim)\n",
    "    print(f\"{word1:9} {word2:9} {max_sim:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Conclusion:** The most similar words are: `banana` & `delicious` with an impressive score of 0.750!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the similarities on GloVe Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car       dog        0.464\n",
      "car       banana     0.219\n",
      "car       delicious  0.068\n",
      "car       baguette   0.046\n",
      "car       jumping    0.516\n",
      "car       hugging    0.278\n",
      "car       election   0.333\n",
      "dog       banana     0.333\n",
      "dog       delicious  0.404\n",
      "dog       baguette   0.018\n",
      "dog       jumping    0.539\n",
      "dog       hugging    0.410\n",
      "dog       election   0.181\n",
      "banana    delicious  0.487\n",
      "banana    baguette   0.450\n",
      "banana    jumping    0.108\n",
      "banana    hugging    0.127\n",
      "banana    election   0.164\n",
      "delicious baguette   0.421\n",
      "delicious jumping    0.042\n",
      "delicious hugging    0.142\n",
      "delicious election   0.028\n",
      "baguette  jumping   -0.075\n",
      "baguette  hugging    0.161\n",
      "baguette  election  -0.091\n",
      "jumping   hugging    0.447\n",
      "jumping   election   0.206\n",
      "hugging   election  -0.076\n"
     ]
    }
   ],
   "source": [
    "glov_sims = []\n",
    "for word1, word2 in combinations(some_words, 2):\n",
    "    max_sim = glove_model.similarity(word1, word2)\n",
    "    glov_sims.append(max_sim)\n",
    "    print(f\"{word1:9} {word2:9} {max_sim:6.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine if two measures correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman's rho SpearmanrResult(correlation=0.5364590589374248, pvalue=0.0032515659964184227)\n"
     ]
    }
   ],
   "source": [
    "# a correlation coefficent of two lists\n",
    "print(\"Spearman's rho\", spearmanr(glov_sims, wn_sims))\n",
    "\n",
    "# Higher correlation (closer to 1.0) means two measures agree with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vector Representations in GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog = [ 0.11008   -0.38781   -0.57615   -0.27714    0.70521    0.53994\n",
      " -1.0786    -0.40146    1.1504    -0.5678     0.0038977  0.52878\n",
      "  0.64561    0.47262    0.48549   -0.18407    0.1801     0.91397\n",
      " -1.1979    -0.5778    -0.37985    0.33606    0.772      0.75555\n",
      "  0.45506   -1.7671    -1.0503     0.42566    0.41893   -0.68327\n",
      "  1.5673     0.27685   -0.61708    0.64638   -0.076996   0.37118\n",
      "  0.1308    -0.45137    0.25398   -0.74392   -0.086199   0.24068\n",
      " -0.64819    0.83549    1.2502    -0.51379    0.04224   -0.88118\n",
      "  0.7158     0.38519  ]\n"
     ]
    }
   ],
   "source": [
    "# Each word is represented as a vector:\n",
    "print('dog =', glove_model['dog'])\n",
    "\n",
    "# matrix of all word vectors is trained as parameters of a language model:\n",
    "# P( target_word | context_word ) = f(word, context ; params)\n",
    "#\n",
    "# Words in a same sentence and in close proximity are in context of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Cosine Similarity (+3pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cosine(v,w) = $\\frac{v \\cdot w}{|v||w|}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6956217"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on equation 6.10 J&M (2019)\n",
    "# https://web.stanford.edu/~jurafsky/slp3/6.pdf\n",
    "#\n",
    "def cosine_sim(v1, v2):\n",
    "    numerator = np.dot(v1, v2)\n",
    "    denomenator = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    out = numerator / denomenator\n",
    "    return out\n",
    "\n",
    "cosine_sim(glove_model['car'], glove_model['automobile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement top-n most similar words (+3pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search in glove_model:\n",
    "def top_n(word, n):\n",
    "    # example: top_n('dog', 3) =  \n",
    "    #[('cat', 0.9218005537986755), \n",
    "    # ('dogs', 0.8513159155845642),\n",
    "    # ('horse', 0.7907583713531494)]\n",
    "    # similar to glove_model.most_similar('dog', topn=3)\n",
    "    \n",
    "    # compute similarity to all other vectors\n",
    "    arr = glove_model.cosine_similarities(\n",
    "        glove_model[word], glove_model.vectors)\n",
    "    \n",
    "    # get sorted indices\n",
    "    # take the last 3 (excluding the word iteself)\n",
    "    res = arr.argsort()[-n-1:-1][::-1]\n",
    "    \n",
    "    # return the word and value at found indices\n",
    "    return [\n",
    "        (glove_model.index2word[x], arr[x])\n",
    "        for x in res\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 0.92180055), ('dogs', 0.85131586), ('horse', 0.7907584)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n('dog', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stuff', 0.86726743),\n",
       " ('crazy', 0.8648681),\n",
       " ('wonderful', 0.84710056),\n",
       " ('really', 0.8386063)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n('fun', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Examine Fairness In Data Driven Word Vectors (+10 pt)\n",
    "\n",
    "Caliskan et al. (2017) argues that word vectors learn human biases from data. \n",
    "\n",
    "Try to replicate one of the tests of the paper:\n",
    "\n",
    "Caliskan, Aylin, Joanna J. Bryson, and Arvind Narayanan. “Semantics derived automatically from language corpora contain human-like biases.” Science\n",
    "356.6334 (2017): 183-186. http://opus.bath.ac.uk/55288/\n",
    "\n",
    "\n",
    "For example on gender bias:\n",
    "- Male names: John, Paul, Mike, Kevin, Steve, Greg, Jeff, Bill.\n",
    "- Female names: Amy, Joan, Lisa, Sarah, Diana, Kate, Ann, Donna.\n",
    "- Career words : executive, management, professional, corporation, salary, office, business, career.\n",
    "- Family words : home, parents, children, family, cousins, marriage, wedding, relatives.\n",
    "\n",
    "\n",
    "Report the average cosine similarity of male names to career words, and compare it with the average similarity of female names to career words. (repeat for family words) \n",
    "\n",
    "tokens in GloVe model are all in lower case.\n",
    "\n",
    "Write at least one sentence to describe your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_names = ['John', 'Paul', 'Mike', 'Kevin', 'Steve', 'Greg', 'Jeff', 'Bill']\n",
    "female_names = ['Amy', 'Joan', 'Lisa', 'Sarah', 'Diana', 'Kate', 'Ann', 'Donna']\n",
    "career_words = ['executive', 'management', 'professional', 'corporation', 'salary', 'office', 'business', 'career']\n",
    "family_words = ['home', 'parents', 'children', 'family', 'cousins', 'marriage', 'wedding', 'relatives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(word_list1, word_list2):\n",
    "    sims = []\n",
    "    for w1 in word_list1:\n",
    "        for w2 in word_list2:\n",
    "            v1 = glove_model[w1.lower()]\n",
    "            v2 = glove_model[w2.lower()]\n",
    "            sim = cosine_sim(v1, v2)\n",
    "            sims.append(sim)\n",
    "    return np.mean(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male vs. career\n",
      "0.35287738\n",
      "\n",
      "female vs. career\n",
      "0.16353184\n",
      "\n",
      "male vs. family\n",
      "0.2753636\n",
      "\n",
      "female vs. family\n",
      "0.37566096\n"
     ]
    }
   ],
   "source": [
    "# male vs. career\n",
    "print(\"male vs. career\")\n",
    "print(compare(male_names, career_words))\n",
    "\n",
    "# female vs. career\n",
    "print(\"\\nfemale vs. career\")\n",
    "print(compare(female_names, career_words))\n",
    "\n",
    "# male vs. family\n",
    "print(\"\\nmale vs. family\")\n",
    "print(compare(male_names, family_words))\n",
    "\n",
    "# female vs. family\n",
    "print(\"\\nfemale vs. family\")\n",
    "print(compare(female_names, family_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
